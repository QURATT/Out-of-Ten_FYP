{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e831290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919fc9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "array_of_labeled_csv=[#'Bioderma_labeled.csv',\n",
    "                      #'erave_labeled.csv',\n",
    "                      #'neutrogena_labeled.csv',\n",
    "                      #'labeled_mayb_foundation.csv',\n",
    "                      #'labeled_mayb_conc.csv',\n",
    "                      #'labeled_hp_envy.csv',\n",
    "                      \n",
    "    #'labeled_Macbook m1.csv',\n",
    "     #                 'labeled_lenovo x1.csv',\n",
    "      #                'labeled_lenovo e14.csv',\n",
    "                       'galaxy7_labeled.csv'\n",
    "                     ]\n",
    "for product in range(len(array_of_labeled_csv)):\n",
    "    data = pd.read_csv(array_of_labeled_csv[product])\n",
    "    data.drop(['Positive','Negative','Neutral','Compound'],axis=1,inplace=True)\n",
    "    data.drop(data[(data['Sentiment'] =='Neutral')].index, inplace=True)\n",
    "    df=data\n",
    "    df['Sentiment'] = df['Sentiment'].replace(['Positive'], 1)\n",
    "    df['Sentiment'] = df['Sentiment'].replace(['Negative'], 0)\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "    X_train = train['Review'].values\n",
    "    X_test = test['Review'].values\n",
    "    y_train = train['Sentiment']\n",
    "    y_test = test['Sentiment']\n",
    "    def tokenize(text): \n",
    "        tknzr = TweetTokenizer()\n",
    "        return tknzr.tokenize(text)\n",
    "\n",
    "    def stem(doc):\n",
    "        return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "    en_stopwords = set(stopwords.words(\"english\")) \n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        analyzer = 'word',\n",
    "        tokenizer = tokenize,\n",
    "        lowercase = True,\n",
    "        ngram_range=(1, 1),\n",
    "        stop_words = en_stopwords)\n",
    "    kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    pipeline_svm = make_pipeline(vectorizer, \n",
    "                                SVC(probability=True, kernel=\"linear\", class_weight=\"balanced\"))\n",
    "\n",
    "    grid_svm = GridSearchCV(pipeline_svm,\n",
    "                        param_grid = {'svc__C': [0.01, 0.1, 1]}, \n",
    "                        cv = kfolds,\n",
    "                        scoring=\"roc_auc\",\n",
    "                        verbose=1,   \n",
    "                        n_jobs=-1) \n",
    "\n",
    "    grid_svm.fit(X_train, y_train)\n",
    "    #print(grid_svm.score(X_test, y_test)*100)\n",
    "    productname=array_of_labeled_csv[product]\n",
    "    accuaracy=grid_svm.score(X_test, y_test)*100\n",
    "    \n",
    "    #print(\"Accuracy : \", accuaracy,\"%\")\n",
    "    f = open(\"Accuracies.txt\", \"a\")\n",
    "    f.write(\"\\n\"+productname+ \" \" + str(accuaracy)+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe43fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
